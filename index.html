
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-Hans" lang="zh-Hans">
  <head>
    <meta charset="UTF-8" />
    <title>Feng-Long Xie's Homepage</title>
    <meta name="robots" content="all" />
    <meta name="author" content="Yalong Bai">
    <meta http-equiv="X-UA-Compatible" content="IE=100" />
    <link rel="stylesheet" type="text/css" href="/css/lemaoliu.css"/>
    <link rel="stylesheet" type="text/css" href="/css/reset.css"/>
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-39157716-1']);
      _gaq.push(['_trackPageview']);

      (function() {
       var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
       ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
       var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
       })();

    </script>
    <script src="/javascripts/jquery/1.5.2/jquery.min.js"></script>
  </head>
  <body>
    <div class="outline"></div>
    <div class="container">
  		<div id="content">
<div class="about">
  <div class="profile">
      
    <div class="info">
      <div class="first-name">Feng-Long</div>
      <div class="last-name">Xie (解奉龙)</div>
      <p class="extra-info">Senior Researcher of Wechat, Tencent</p>
	  	  <p class="extra-info">E-MAIL: xiefenglong7825 AT gmail DOT com</p>

   
    </div>
  </div>
 <div class="about-page">
    <div class="line-1">
      <h1>Education</h1>
	<li>2014.9 -- Now: Joint Phd Candidate in Computer Science and Technology, Harbin Institute of Technology and Microsoft Research Asia. Supervisor: Frank K. Soong and Haifeng Li</li>
	<li>2012.9 -- 2014.7: M.S. in Computer Science and Technology, School of Computer Science And Technology, Harbin Institute of Technology. Supervisor: Frank K. Soong and Haifeng Li</li> 
    <li>2008.9 -- 2012.7: B.S. in Computer Science and Technology, School of Honor, Harbin Institute of Technology.   
   </div>
    <div class="line-2">
      <h1>Selected Honors and Awards</h1>
	  <li>ISCA grants, 2016</li>
	<li><a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/">Microsoft Fellowship</a>, 2015 (13 winners in Asia-Pacific Region)</li> 
	<li>Outstanding Master Thesis in HIT, 2012</li>
	<li>Outstanding Undergraduates in Hei-Longjiang Province, 2012</li>
	<li>National Graduate Scholarship, 2011 </li>
	<li><a href="http://www.msra.cn/zh-cn/connections/talents/undergrads/2011youngscholaraward.aspx">Microsoft Young Fellowship</a>, 2011 (30 winners from top 10 universities of China)</li>
	<li>First Prize in <a href="http://www.mcm.edu.cn/html_cn/node/f9036698349f1ef471e62eac18d5db30.html">CUMCM</a>, 2010. (Two teams in HIT won the first Prize) 
	<li>National Undergraduate Scholarship, 2009 </li>
	
    </div>
   <div class="line-3">
	<h1>Social practice and Work Experience</h1>
	<h2>Research Intern, Microsoft Research Asia, Speech Group (2014.07 -- Now)</h2>
	<p>During the internship, my research focused on Cross-Lingual TTS synthesis, voice conversion with Deep Neural Network</p>
	<h2>Research Intern, Microsoft Research Asia, Speech Group (2013.06 -- 2014.07)</h2>
	<p>During the internship, my research focused on how to improve performance of the Neural Network based voice conversion, including</p>
		<li> DBN or layer-wise BP pre-training for Neural Network</li>
		<li> Change training criterion from Minimum Frame Error to Minimum Sequence Error</li>
		<li> Wavelet decomposed pitch conversion in Neural Network frame work</li> 
	<h2>Research Intern, Microsoft Research Asia, Speech Group (2012.01-2012-07)</h2>
	<p>During the internship, I was trying to generalize cross validation to decision tree clustering with Minimum Generation Error training criterion to improve the robustness of HMM-based TTS and alleviate the over-fitting problem associated with the conventional approach without using CV.</p>
  </div>

	 <div class="line-5">
      <section>
      <h1>Project Demos</h1>
      <h2>I Frame Selection in SI-DNN Phonetic Space with WaveNet Vocoder for Voice Conversion </h2>
      <p>You can check the details in [2]. Here is the Demo</a></p>
	   <table width="604" height="69" border="1" align="center">
  <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Source Speaker&nbsp;&nbsp;</span></td>
      <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Voice Conversion&nbsp;&nbsp;</span></td>
		    <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Target Speaker&nbsp;&nbsp;</span></td>
</audio>&nbsp;&nbsp;</td>
  </tr>
   
   <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="iscslpdemo/100030_nrs.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="iscslpdemo/100030_4.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
	      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="iscslpdemo/100030_nr.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
  </tr>
  
</table> 


	  <h2>II A KL divergence and Deep Neural Network Approach to Voice Conversion</h2>
      <p>You can check the details in [3]. Here is the Demo</a></p>
	   <table width="604" height="69" border="1" align="center">
  <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Source Speaker&nbsp;&nbsp;</span></td>
      <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Voice Conversion&nbsp;&nbsp;</span></td>
	     <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">TTS upperbound&nbsp;&nbsp;</span></td>
		    <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">Target Speaker&nbsp;&nbsp;</span></td>
</audio>&nbsp;&nbsp;</td>
  </tr>
   
   <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/s1.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/KLD-DNN1.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
	      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/TTS1.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
		    <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/t1.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
  </tr>
  
  

   
   <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/s2.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/KLD-DNN2.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
	      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/TTS2.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
		    <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/t2.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
  </tr>
  
   <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/s3.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/KLD-DNN3.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
	      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/TTS3.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
		    <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/vc/t3.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
  </tr>
 	</table> 
	  <h2>III Matching and Rendering Speech across Speaker and Language Difference</h2>
      <p>You can check the details in [4]. Here is the mix-code (English, Mandarine)Demo. This mix-code TTS is trained with only the this speaker's English speech. The transcription of the sample is 
	  "Driving directions to Beijing railway station. Head south on 中关村南大街, then toward 大慧寺路, turn left at 白石新桥, continue onto 西直门外大街"</a></p>
	   <table width="604" height="69" border="1" align="center">
  <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">English natural recording&nbsp;&nbsp;</span></td>
      <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">mix-code TTS (previous state)&nbsp;&nbsp;</span></td>
	     <td align="center" valign="middle">&nbsp;&nbsp;<span class="wav_name">mix-code TTS (proposed KLD-DNN )&nbsp;&nbsp;</span></td>
		
</audio>&nbsp;&nbsp;</td>
  </tr>
   
   <tr>
   <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/mixcodetts/natural.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/mixcodetts/Hon_baseline.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
	      <td align="center" valign="middle">&nbsp;&nbsp;<audio controls>
  <source src="personpagedemo/mixcodetts/Hon_KLDDNN.wav" type="audio/wav">  

</audio>&nbsp;&nbsp;</td>
		    
  </tr>
  
  

  
 	</table> 
	  
	  <h2>IV Sequence Error Minimization Training of Neural Network for Voice Conversion</h2>
      <p>You can check the details in [5]and [6].</p>
	

 
      </section>
    </div>
	
	
	 <div class="line-4">
      <section>
      <h1>Publications</h1>
      <li>[1] <b>Feng-Long Xie</b>, Frank K. Soong, Haifeng Li, "Voice Conversion with SI-DNN and KL Divergence based Mapping without Parallel Training Data" Speech Communication, 2019 </li>
      <li>[2] <b>Feng-Long Xie</b>, Frank K. Soong, Haifeng Li, "Frame Selection in SI-DNN Phonetic Space with WaveNet Vocoder for Voice Conversion without Parallel Training Data" in Proc. ISCSLP, 2018 </li>
	  <li>[3] <b>Feng-Long Xie</b>, Frank K. Soong, Haifeng Li, "A KL Divergence and DNN Approach to Voice Conversion without parallel training sentences" in Proc. Interspeech, 2016 </li>
    <li>[4] <b>Feng-Long Xie</b>, Frank K. Soong, Haifeng Li, "A KL Divergence and DNN Approach to Cross-lingual TTS" in Proc. ICASSP, 2016 <a href="publishedpaper/icassp2016.pdf">(PDF)</a></li>
	<li>[5] <b>Feng-Long Xie</b>, Yao Qian, Frank K. Soong, Haifeng Li, "Sequence Error (SE) Minimization Training of Neural Network for Voice Conversion" in Proc. Interspeech, 2014 <a href="publishedpaper/VC_MSE.pdf">(PDF)</a></li>
	<Li>[6] <b>Feng-Long Xie</b>, Yao Qian, Frank K. Soong, Haifeng Li, "Pitch Transformation in Neural Network based Voice Conversion" in Proc. ISCSLP, 2014 <a href="publishedpaper/pitchNN.pdf">(PDF)</a> </li>
	<Li>[7] Yuchen Fan, Yao Qian, <b>Feng-Long Xie</b>, Frank K. Soong, Statistical Parametric TTS Synthesis with Bidirectional LSTM Recurrent Neural Networks" in Proc. Interspeech, 2014</Li>
	<li>[8] <b>Feng-Long Xie</b>, Yi-Jian Wu, Frank K.Soong. "Cross Validation and Minimum Generation Error for improved model clustering in HMM-based TTS" in Proc. ISCSLP 2012 <a href="publishedpaper/ISCSLP2012.pdf">(PDF)</a> </li>
      </section>
    </div>
	
    <div class="line-6">
      <section id="skills">
      <h1>Mastered Technology and Research Interests</h1>
      <ol class="jellybean">
       	<li> Speech Processing</li>
        <li> Voice Conversion </li>
        <li> Speech Synthesis </li>
        <li> Deep Learning  </li>
        <li> C++ </li>
        <li> Perl </li>
        <li> Python </li>
        <li> Matlab </li>
        <li> HTK </li>
      </ol>
      </section>
    </div>
	

  
<!--
    <div class="line-5">
      <section id="internet-footprint">
      <h1>Downloads</h1>
      <p><a href="/download1">Parser</a> - parser.<br />
      <a href="http://www.pixiv.net/member.php?id=4798189">SVM</a> - write something.
      </p>
      </section>
    </div>
-->
  </div>
</div>
  		</div>
    </div>
  </body>
</html>